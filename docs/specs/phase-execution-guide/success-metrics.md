# Success Metrics

### After Wave 0:
- [ ] Quality baseline established (<90% â†’ measure actual)
- [ ] Data normalizer functional
- [ ] Regression baseline captured

### After Wave 1:
- [ ] Kill-switch verdicts displaying (PASS/WARNING/FAIL)
- [ ] [H]/[S] markers distinguishing criteria
- [ ] Severity scores accurate

### After Wave 2:
- [ ] Monthly costs displayed in deal sheets
- [ ] $4k warnings appearing when applicable
- [ ] Cost efficiency contributing to scores (40 pts)

### After Wave 3:
- [ ] Pydantic validation catching errors
- [ ] Invalid data rejected gracefully
- [ ] Validation errors logged

### After Wave 4:
- [ ] AI inference functional for missing fields
- [ ] Confidence scores assigned
- [ ] Cost per inference <$0.01

### After Wave 5:
- [ ] Quality score >=95% (or documented gap <2%)
- [ ] Field lineage tracked for all properties
- [ ] CI gate functional

### After Wave 6:
- [ ] All documentation updated
- [ ] All tests passing (unit + integration + regression)
- [ ] End-to-end workflow functional

---
