# enrichment_data.json Field Cleanup Plan

**Status:** DOCUMENTATION ONLY - No changes to enrichment_data.json at this time

**Last Updated:** 2025-12-01

**Current Structure:** 35 properties with 117 unique fields in list format

## Executive Summary

The enrichment_data.json contains legacy and redundant fields accumulated during development. This document catalogs fields for future cleanup without modifying the current data. Three main categories need attention:

1. **Synonym Fields** - Duplicate scoring fields with different naming conventions
2. **Computed Fields** - Runtime calculations stored unnecessarily
3. **Orphaned Metadata** - Source and confidence fields with unclear utility

## 1. Synonym Fields (7 fields to consolidate)

These fields have canonical equivalents and should eventually use only one name:

### 1.1 Ceiling Height vs High Ceilings
- **Current:** `ceiling_height_score`, `high_ceilings_score`
- **Canonical:** `high_ceilings_score`
- **Rationale:** Section C scoring system uses `high_ceilings_score`. `ceiling_height_score` is legacy naming.
- **Dependencies:** None
- **Migration Script:** Keep `high_ceilings_score`, remove `ceiling_height_score` and `ceiling_height_score_source`
- **Data Sample:** Both exist in all/most properties with potentially different values

### 1.2 Kitchen Quality vs Kitchen Layout
- **Current:** `kitchen_quality_score`, `kitchen_layout_score`
- **Canonical:** `kitchen_layout_score`
- **Rationale:** Scoring system uses `kitchen_layout_score`. `kitchen_quality_score` is older variant.
- **Dependencies:** Scoring configuration and templates may reference both
- **Migration Script:** Keep `kitchen_layout_score`, remove `kitchen_quality_score` and `kitchen_quality_score_source`
- **Data Sample:** `kitchen_layout_score` is 9.0, `kitchen_quality_score` is 5.0 in example - different sources/assessment times

### 1.3 Master Quality vs Master Suite
- **Current:** `master_quality_score`, `master_suite_score`
- **Canonical:** `master_suite_score`
- **Rationale:** Section C scoring and templates use `master_suite_score`. `master_quality_score` is legacy.
- **Dependencies:** Deal sheet templates and scoring configuration
- **Migration Script:** Keep `master_suite_score`, remove `master_quality_score` and `master_quality_score_source`
- **Data Sample:** Example has `master_suite_score=6.0`, `master_quality_score=5.0`

### 1.4 Laundry Area vs Laundry
- **Current:** `laundry_score`, `laundry_area_score`
- **Canonical:** `laundry_area_score`
- **Rationale:** Config uses `laundry_area_score`. `laundry_score` is shorter, legacy name.
- **Dependencies:** Scoring weights configuration
- **Migration Script:** Keep `laundry_area_score`, remove `laundry_score` and `laundry_score_source`
- **Data Sample:** Both exist with identical values (5.0)

### 1.5 List Price vs Price
- **Current:** `list_price`, `price`
- **Canonical:** `price`
- **Rationale:** CSV header uses `price`. `list_price` is redundant property-level storage.
- **Dependencies:** Cost estimation queries `price` (not `list_price`)
- **Migration Script:** Remove `list_price` - reference CSV's `price` column directly
- **Data Sample:** Example has both = 475000

### 1.6 Fireplace Score Clarification
- **Current:** `fireplace_score`, potentially `fireplace_present`, `interior_fireplace_score`
- **Issue:** Unclear if `fireplace_score` represents presence (binary) or quality (0-10)
- **Recommendation:**
  - Decide on single field: either `fireplace_present` (bool) or `fireplace_score` (0-10 quality)
  - Document the schema in `DESIGN.md`
- **Data Sample:** `fireplace_score=6.0` suggests quality score, not boolean

---

## 2. Computed Fields (6 fields to remove)

These fields are computed during the analysis pipeline and should NOT be persisted in enrichment_data.json:

### 2.1 cost_breakdown
- **Type:** `dict`
- **Content:** Breakdown of cost components (mortgage, taxes, insurance, pool, etc.)
- **Why Remove:** Generated by `CostEstimationService.estimate()` at runtime
- **Used By:** Deal sheet templates, console reporter, cost efficiency scoring
- **Regeneration:** Call `CostEstimationService().estimate(property)` when needed
- **Impact:** Low - always computed from stored fields (price, tax_annual, hoa_fee, etc.)
- **Location:** Lines 142-146 in `src/phx_home_analysis/services/cost_estimation/estimator.py`

### 2.2 monthly_cost
- **Type:** `float`
- **Content:** Calculated monthly payment total
- **Why Remove:** Computed from price, tax_annual, hoa_fee, pool equipment age, solar_lease_monthly
- **Used By:** Deal sheets, cost efficiency scoring, budget validation
- **Regeneration:** `CostEstimationService().estimate(property).monthly_total`
- **Impact:** Low - deterministic computation from stored fields
- **Location:** References in `scripts/deal_sheets/renderer.py:168`

### 2.3 kill_switch_passed
- **Type:** `bool`
- **Content:** Whether property passes kill-switch filtering
- **Why Remove:** Computed from HOA fee, bed/bath counts, sewer_type, year_built, lot_sqft, garage_spaces
- **Used By:** Filtering, reporting, triage (but NOT for final analysis)
- **Regeneration:** `KillSwitchEvaluator.evaluate(property)`
- **Impact:** Medium - needed for filtering, but should be computed not stored
- **Location:** `scripts/lib/kill_switch.py` and `src/phx_home_analysis/services/kill_switch/`

### 2.4 kill_switch_failures
- **Type:** `list`
- **Content:** List of failed criteria (e.g., ["hoa_present", "low_beds"])
- **Why Remove:** Diagnostic output, not persistent state
- **Used By:** Logging, reporting, debugging
- **Regeneration:** `KillSwitchEvaluator.evaluate(property).failures`
- **Impact:** Low - useful for debugging but not required for analysis
- **Location:** Part of kill-switch evaluation flow

### 2.5 sqft
- **Type:** `float` (2241 in example)
- **Content:** Living square footage
- **Why Remove:** Duplicate of CSV column `sqft`
- **Used By:** Scoring, area-per-bedroom calculations
- **Regeneration:** Read from CSV directly
- **Impact:** High - creates data duplication and sync issues
- **Location:** Should reference CSV, not enrichment layer

### 2.6 price
- **Type:** `int` (475000 in example)
- **Content:** Property listing price
- **Why Remove:** Duplicate of CSV column `price`
- **Used By:** Cost estimation, scoring, reporting
- **Regeneration:** Read from CSV directly
- **Impact:** High - primary source of data duplication
- **Location:** Should reference CSV, not enrichment layer

---

## 3. Orphaned Metadata Fields (12+ fields)

These fields track data provenance via `*_source` and `*_confidence` patterns. Assess whether they're essential for LineageTracker:

### 3.1 Source Fields (17 total)

| Field | Current Value(s) | Used By | Decision |
|-------|-----------------|---------|----------|
| `aesthetics_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `ceiling_height_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `fireplace_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `high_ceilings_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `kitchen_layout_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `kitchen_quality_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `laundry_area_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `laundry_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `master_quality_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `master_suite_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `natural_light_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `safety_neighborhood_score_source` | `default_pending_assessment` | LineageTracker? | INVESTIGATE |
| `data_source` | (varies) | Unknown | ORPHANED? |
| `distance_to_park_miles_source` | (varies) | Unknown | ORPHANED? |
| `orientation_source` | (varies) | Unknown | ORPHANED? |
| `parks_data_source` | `web_research_85306` | Audit trail? | INVESTIGATE |
| `safety_data_source` | `web_research_85306` | Audit trail? | INVESTIGATE |

**Recommendation:** Before cleanup, verify:
1. Which `*_source` fields are actively queried by LineageTracker
2. Whether `field_lineage.json` (LineageTracker's file) is the proper home for this data
3. If enrichment_data.json should store sources at all vs. delegating to LineageTracker

### 3.2 Confidence Fields (6 total)

| Field | Current Value(s) | Purpose | Decision |
|-------|-----------------|---------|----------|
| `assessment_confidence` | (varies) | Overall assessment confidence | UNCLEAR |
| `confidence_breakdown` | (dict?) | Component confidences | UNCLEAR |
| `hvac_age_confidence` | `estimated_replacement_cycle` | HVAC estimation quality | KEEP? |
| `image_assessment_confidence` | (varies) | Image quality score | INVESTIGATE |
| `interior_assessment_confidence` | (varies) | Interior scoring quality | INVESTIGATE |
| `interior_confidence` | (varies) | Interior section confidence | INVESTIGATE |
| `pool_equipment_age_confidence` | `estimated_replacement_cycle` | Pool estimation quality | KEEP? |
| `roof_age_confidence` | `estimated_multiple_replacements` | Roof estimation quality | KEEP? |
| `section_c_confidence` | (varies) | Interior section confidence | INVESTIGATE |

**Recommendation:**
- Age estimation confidence fields (`hvac_age_confidence`, `pool_equipment_age_confidence`, `roof_age_confidence`) appear intentional - KEEP for now
- Assessment confidence fields suggest scoring reliability tracking - CONSOLIDATE into single `scoring_confidence` with detailed breakdown in LineageTracker
- Eliminate duplicates like `interior_confidence` vs `interior_assessment_confidence`

### 3.3 Computed Section Fields (5 total)

These appear to be intermediate scoring results:

| Field | Type | Purpose |
|-------|------|---------|
| `score_interior` | float | Section C total |
| `score_location` | float | Section A total |
| `score_lot_systems` | float | Section B total |
| `total_score` | float | Grand total |
| `scored_at` | datetime? | Scoring timestamp |

**Recommendation:**
- These are scoring artifacts that should be in `phx_homes_ranked.csv` output, not in enrichment_data.json
- If needed during pipeline, compute them dynamically in PropertyScorer
- Remove from persistent storage to avoid stale scores

### 3.4 Interior Section Aliases (8 fields)

These duplicate the main score fields with `interior_` prefix:

| Main Field | Interior Alias |
|-----------|----------------|
| `aesthetics_score` | (no interior version but follows pattern) |
| `high_ceilings_score` | `interior_ceilings_score` |
| `fireplace_score` | `interior_fireplace_score` |
| `natural_light_score` | `interior_light_score` |
| `kitchen_layout_score` | `interior_kitchen_score` |
| `master_suite_score` | `interior_master_score` |
| `laundry_area_score` | `interior_laundry_score` |

**Recommendation:** Choose ONE naming convention:
- Option A: Use main field names only (`high_ceilings_score` not `interior_ceilings_score`)
- Option B: Use `interior_` prefix consistently for Section C
- Document choice in design spec

---

## 4. Fields to Investigate Before Cleanup

### 4.1 Data Sources (Generic)
```
data_source             (what data comes from what source?)
distance_to_park_miles_source
orientation_source
parks_data_source       (web_research_85306)
safety_data_source      (web_research_85306)
```

**Action:** Grep codebase for references. If unused, flag for removal.

### 4.2 Assessment Confidence Proliferation
```
assessment_confidence
image_assessment_confidence
interior_assessment_confidence
interior_confidence
section_c_confidence
```

Multiple fields suggest poor abstraction. Should consolidate into single confidence tracking system.

### 4.3 Scoring Timestamp
```
scored_at           (datetime when scoring occurred?)
```

**Action:** Verify if needed for audit trail. If yes, move to LineageTracker or Phase 4 output file.

---

## 5. Migration Strategy (Future)

### Phase 1: Audit (Week 1)
- [ ] Search codebase for references to all `*_source` fields
- [ ] Search for references to all `*_confidence` fields
- [ ] Verify which confidence fields are used by LineageTracker
- [ ] Document findings in `INVESTIGATION.md`

### Phase 2: Consolidation (Week 2)
- [ ] Consolidate synonym fields (ceiling, kitchen, master, laundry)
- [ ] Remove `list_price` and `sqft` from enrichment layer
- [ ] Consolidate confidence fields into single system
- [ ] Update config/templates to use canonical field names

### Phase 3: Removal (Week 3)
- [ ] Remove computed fields (`cost_breakdown`, `monthly_cost`, `kill_switch_*`, section scores)
- [ ] Remove orphaned `*_source` fields not used by LineageTracker
- [ ] Update all references in code to compute/fetch from proper sources
- [ ] Add validation to prevent re-addition of computed fields

### Phase 4: Validation (Week 4)
- [ ] Run full pipeline with cleaned schema
- [ ] Verify deal sheets generate correctly
- [ ] Verify scoring is unaffected
- [ ] Update tests to match new schema

---

## 6. Cleanup Script Template

**File:** `scripts/cleanup_enrichment_data.py` (SKELETON ONLY)

```python
#!/usr/bin/env python3
"""Clean up enrichment_data.json based on documented plan.

DANGER: This script modifies production data. Use --dry-run first.

Usage:
    python scripts/cleanup_enrichment_data.py --dry-run      # Show changes
    python scripts/cleanup_enrichment_data.py --apply         # Apply changes
    python scripts/cleanup_enrichment_data.py --phase=1       # Phase 1 only
"""

import argparse
import json
from pathlib import Path
from typing import Any

# Phase 1: Remove synonym duplicates
SYNONYM_REMOVALS = {
    "ceiling_height_score": "high_ceilings_score",
    "ceiling_height_score_source": None,  # Remove entirely
    "kitchen_quality_score": "kitchen_layout_score",
    "kitchen_quality_score_source": None,
    "master_quality_score": "master_suite_score",
    "master_quality_score_source": None,
    "laundry_score": "laundry_area_score",
    "laundry_score_source": None,
    "list_price": None,  # Duplicate of CSV
}

# Phase 2: Remove computed fields
COMPUTED_FIELDS = {
    "cost_breakdown",
    "monthly_cost",
    "kill_switch_passed",
    "kill_switch_failures",
    "sqft",  # Duplicate of CSV
    "price",  # Duplicate of CSV
}

# Phase 3: Investigate before removal
ORPHANED_SOURCES = {
    "data_source",
    "distance_to_park_miles_source",
    "orientation_source",
    # ... (17 total - see section 3.1)
}

ORPHANED_CONFIDENCE = {
    "assessment_confidence",
    "confidence_breakdown",
    "image_assessment_confidence",
    "interior_assessment_confidence",
    "interior_confidence",
    "section_c_confidence",
    # Keep: hvac_age_confidence, pool_equipment_age_confidence, roof_age_confidence
}

INTERIOR_ALIASES = {
    "interior_ceilings_score",
    "interior_fireplace_score",
    "interior_kitchen_score",
    "interior_laundry_score",
    "interior_light_score",
    "interior_master_score",
}


def cleanup_property(prop: dict[str, Any], phase: int) -> dict[str, Any]:
    """Remove fields based on cleanup phase.

    Args:
        prop: Property dictionary from enrichment_data.json
        phase: Cleanup phase (1, 2, or 3)

    Returns:
        Cleaned property dictionary
    """
    cleaned = prop.copy()

    if phase >= 1:
        for field, canonical in SYNONYM_REMOVALS.items():
            if canonical is None:
                cleaned.pop(field, None)  # Remove entirely
            else:
                # Could validate they have same value before removal
                cleaned.pop(field, None)

    if phase >= 2:
        for field in COMPUTED_FIELDS:
            cleaned.pop(field, None)

    if phase >= 3:
        for field in ORPHANED_SOURCES:
            cleaned.pop(field, None)
        for field in ORPHANED_CONFIDENCE:
            cleaned.pop(field, None)
        for field in INTERIOR_ALIASES:
            cleaned.pop(field, None)

    return cleaned


def main():
    parser = argparse.ArgumentParser(description="Clean up enrichment_data.json")
    parser.add_argument("--dry-run", action="store_true", help="Show changes without applying")
    parser.add_argument("--apply", action="store_true", help="Apply changes (dangerous!)")
    parser.add_argument("--phase", type=int, default=1, help="Cleanup phase (1-3)")
    parser.add_argument("--backup", action="store_true", help="Create backup before applying")
    args = parser.parse_args()

    data_file = Path("data/enrichment_data.json")

    # Load data
    with open(data_file) as f:
        data = json.load(f)

    # Apply cleanup
    cleaned_data = [cleanup_property(prop, args.phase) for prop in data]

    if args.dry_run:
        # Show diff
        print(f"Would remove {len(data) - len(cleaned_data)} properties")
        print(f"Fields removed from each property: ...")
        return

    if args.apply:
        if args.backup:
            backup_file = data_file.with_suffix('.json.backup')
            backup_file.write_text(data_file.read_text())
            print(f"Backup created: {backup_file}")

        with open(data_file, 'w') as f:
            json.dump(cleaned_data, f, indent=2)

        print(f"Cleaned {len(data)} properties (phase {args.phase})")


if __name__ == "__main__":
    main()
```

---

## 7. Impact Analysis

### Severity by Field Category

| Category | Impact | Risk | Effort |
|----------|--------|------|--------|
| Synonym Fields (7) | Low | Low | Low (1 day) |
| Computed Fields (6) | Medium | Medium | Medium (2-3 days) |
| Orphaned Metadata (12+) | Low-Medium | Low | Medium (1-2 days) |

### Dependencies to Verify

1. **Scoring Configuration** (`src/phx_home_analysis/config/`)
   - Which field names are referenced in weights?
   - Will `high_ceilings_score` vs `ceiling_height_score` cause mismatches?

2. **Deal Sheet Templates** (`scripts/deal_sheets/templates.py`)
   - Which fields are rendered?
   - Will consolidation break rendering?

3. **Console Reporter** (`src/phx_home_analysis/reporters/`)
   - What's displayed?
   - Any formatting assumptions?

4. **LineageTracker** (`src/phx_home_analysis/services/quality/lineage.py`)
   - Does it actually use `*_source` fields from enrichment_data.json?
   - Or does it maintain separate `field_lineage.json`?

### Fields Used by LineageTracker

**Finding:** LineageTracker uses dedicated `data/field_lineage.json` file, NOT the enrichment_data.json source fields.

- `record_field(property_hash, field_name, source, confidence)` writes to `field_lineage.json`
- `get_field_lineage()` reads from `field_lineage.json`
- `*_source` and `*_confidence` in enrichment_data.json are DUPLICATES of LineageTracker's tracking

**Implication:** `*_source` and `*_confidence` fields in enrichment_data.json can be removed without impact - they're redundant with LineageTracker.

---

## 8. Validation Checklist

Before removal, verify:

- [ ] All code references to each field documented
- [ ] Alternative source identified (LineageTracker, CSV, compute function)
- [ ] Tests updated to not expect removed fields
- [ ] Configuration files reviewed for field name dependencies
- [ ] Deal sheet templates produce same output
- [ ] Scoring unchanged (audit sample of 5 properties)
- [ ] Backup created before applying
- [ ] CI/CD pipeline passes after cleanup

---

## 9. Related Documents

- `src/DESIGN.md` - Property data model design
- `scripts/lib/kill_switch.py` - Kill-switch evaluation logic
- `src/phx_home_analysis/services/cost_estimation/estimator.py` - Cost computation
- `src/phx_home_analysis/services/quality/lineage.py` - Lineage tracking system
- `scripts/deal_sheets/templates.py` - Field usage in reporting

---

## 10. Conclusion

**Current Status:** enrichment_data.json has accumulated 117 fields over development, with clear categories for consolidation.

**Recommendation:**
1. Execute Phase 1 (synonyms) at next sprint - low risk, immediate benefit
2. Execute Phase 2 (computed fields) during cost estimation refactor - medium effort, high benefit
3. Pause Phase 3 until LineageTracker fully validated

**Next Steps:**
1. Run investigation script from Section 7 to verify usage
2. Create `INVESTIGATION.md` with findings
3. Update design spec with canonical field names
4. Add validation to pipeline to prevent re-addition of removed fields

---

*Document maintained by: Claude Code*
*Last audit: 2025-12-01*
*Fields documented: 117*
*Cleanup phases planned: 3*
